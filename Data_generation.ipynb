{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41fe89a-40f3-4835-877a-321915fd52e4",
   "metadata": {},
   "source": [
    "importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c070db56-a1d4-430d-b5ec-10bb88c52596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d252e-f5e3-4eb1-bc4b-1378f3926cc0",
   "metadata": {},
   "source": [
    "Collecting the channel ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a9b05cf-b8fa-404d-9344-04a93e490389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key ='XXXX' #generate your own API key and add here\n",
    "channel_ids = ['UCeVMnSShP_Iviwkknt83cww',# codewithharry\n",
    "             'UCBwmMxybNva6P_5VmxjzwqA', # apna college\n",
    "             'UCnz-ZXXER4jOvuED5trXfEA', # techTFQ\n",
    "             'UCmDgY7fZKvgatlO0Tib2ggQ', # buzzfeed india\n",
    "             'UCbuj4kbjP05NLiWUbpSuBPw', # monkey magic\n",
    "               # more channel ids here\n",
    "             ]\n",
    "\n",
    "\n",
    "# Get credentials and create an API client\n",
    "youtube=build('youtube','v3',developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5560db9-a2f0-4ebb-b684-def30499ad3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to get channel statistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f539ba1e-353a-4449-b769-9a34e273dc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=','.join(channel_ids))\n",
    "    response = request.execute() \n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(Channel_name = response['items'][i]['snippet']['title'],\n",
    "                    Subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    Views = response['items'][i]['statistics']['viewCount'],\n",
    "                    Total_videos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlist_id = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "    \n",
    "    return all_data\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5734f3dd-9131-4357-9c20-ab66e5233c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_statistics=get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b00d3e60-1d0f-4a77-82ac-82884aa54ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_data= pd.DataFrame(channel_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5eace74c-0907-401f-b0df-cd57ecd8f8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# changing the data type to numeric from object of certain columns\n",
    "channel_data['Subscribers'] = pd.to_numeric(channel_data['Subscribers'])\n",
    "channel_data['Views'] = pd.to_numeric(channel_data['Views'])\n",
    "channel_data['Total_videos'] = pd.to_numeric(channel_data['Total_videos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1555f84f-11b5-4b94-bc9f-6c934a414652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adding the data to a csv file\n",
    "channel_data.to_csv('YT_Channel_details.csv')\n",
    "#channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79ce9af5-5c29-428a-9da7-da40b703ce33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add the channel name for which you want to gather the data\n",
    "playlist_id = channel_data.loc[channel_data['Channel_name']=='techTFQ', 'playlist_id'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18034b84-503c-40e9-81f0-cfe11c236b78",
   "metadata": {},
   "source": [
    "get video ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "134cf050-9eaf-4c35-bf08-aa21082bb714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "    \n",
    "    while more_pages:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                        part='contentDetails',\n",
    "                        playlistId = playlist_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "            response = request.execute()\n",
    "    \n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "            \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f98aa43e-767c-48bb-983b-e890c28f77d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_ids = get_video_ids(youtube, playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb598bcc-0985-40c9-9418-3a3165f45b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20ab88-5787-4106-8f53-c729c2c3afab",
   "metadata": {},
   "source": [
    "get each video information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "027e4db9-f0e4-4f26-bd28-6b4ef7c86db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):\n",
    "    all_video_stats = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "                    part='snippet,statistics',\n",
    "                    id=','.join(video_ids[i:i+50]))\n",
    "        response = request.execute()\n",
    "         \n",
    "        for video in response['items']:\n",
    "            video_stats = dict(Video_id = video['id'],\n",
    "                               Title = video['snippet']['title'],\n",
    "                               Published_date = video['snippet']['publishedAt'],\n",
    "                               Views = video['statistics']['viewCount'],\n",
    "                               Likes = video['statistics']['likeCount'],\n",
    "                               Comments = video['statistics']['commentCount'],\n",
    "                               Channel_Title = video['snippet']['channelTitle']\n",
    "                               )\n",
    "            all_video_stats.append(video_stats)\n",
    "        \n",
    "    return all_video_stats\n",
    "    #return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "adeaaeb6-ab6f-461c-a935-63f628d248dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_details = get_video_details(youtube, video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f9dc071-4c03-4418-bbd9-067691de45ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_data = pd.DataFrame(video_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd2061be-75c5-411d-9e04-6f75eddf024e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Published_date</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Channel_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7skZzocEU6c</td>\n",
       "      <td>Solving a Complex SQL Interview problem | Prac...</td>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>19622</td>\n",
       "      <td>578</td>\n",
       "      <td>78</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZGaRcDxj8I</td>\n",
       "      <td>REAL SQL Interview Problem | Hierarchical data...</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>10630</td>\n",
       "      <td>492</td>\n",
       "      <td>47</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rBPQ5fg_kiY</td>\n",
       "      <td>Complete guide to Database Normalization in SQL</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>21888</td>\n",
       "      <td>1177</td>\n",
       "      <td>177</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hvwltYazuQo</td>\n",
       "      <td>SQL Live class on Lighthall | Learn SQL from B...</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>10264</td>\n",
       "      <td>236</td>\n",
       "      <td>148</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a-hFbr-4VQQ</td>\n",
       "      <td>How to learn SQL for free | Roadmap to learnin...</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>225105</td>\n",
       "      <td>7727</td>\n",
       "      <td>315</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1aybOgni7lI</td>\n",
       "      <td>How to install PostgreSQL on Mac OS | Install ...</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>57087</td>\n",
       "      <td>580</td>\n",
       "      <td>92</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>j09EQ-xlh88</td>\n",
       "      <td>Learn What is Database | Types of Database | DBMS</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>165789</td>\n",
       "      <td>3098</td>\n",
       "      <td>110</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>7nzTDrio7vY</td>\n",
       "      <td>Do you need a Smartwatch</td>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>11213</td>\n",
       "      <td>182</td>\n",
       "      <td>46</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>J-uCLHTIWZ4</td>\n",
       "      <td>MacBook Pro 13 2020  One Week Later Review</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>1338</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>_BMPh5M4BIY</td>\n",
       "      <td>MacBook Pro 13 2020 Unboxing</td>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>2373</td>\n",
       "      <td>88</td>\n",
       "      <td>29</td>\n",
       "      <td>techTFQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Video_id                                              Title  \\\n",
       "0   7skZzocEU6c  Solving a Complex SQL Interview problem | Prac...   \n",
       "1   LZGaRcDxj8I  REAL SQL Interview Problem | Hierarchical data...   \n",
       "2   rBPQ5fg_kiY    Complete guide to Database Normalization in SQL   \n",
       "3   hvwltYazuQo  SQL Live class on Lighthall | Learn SQL from B...   \n",
       "4   a-hFbr-4VQQ  How to learn SQL for free | Roadmap to learnin...   \n",
       "..          ...                                                ...   \n",
       "82  1aybOgni7lI  How to install PostgreSQL on Mac OS | Install ...   \n",
       "83  j09EQ-xlh88  Learn What is Database | Types of Database | DBMS   \n",
       "84  7nzTDrio7vY                           Do you need a Smartwatch   \n",
       "85  J-uCLHTIWZ4         MacBook Pro 13 2020  One Week Later Review   \n",
       "86  _BMPh5M4BIY                       MacBook Pro 13 2020 Unboxing   \n",
       "\n",
       "   Published_date   Views  Likes  Comments Channel_Title  \n",
       "0      2023-03-21   19622    578        78       techTFQ  \n",
       "1      2023-03-14   10630    492        47       techTFQ  \n",
       "2      2023-03-07   21888   1177       177       techTFQ  \n",
       "3      2023-01-26   10264    236       148       techTFQ  \n",
       "4      2022-12-28  225105   7727       315       techTFQ  \n",
       "..            ...     ...    ...       ...           ...  \n",
       "82     2020-11-16   57087    580        92       techTFQ  \n",
       "83     2020-08-30  165789   3098       110       techTFQ  \n",
       "84     2020-07-12   11213    182        46       techTFQ  \n",
       "85     2020-06-29    1338     70        20       techTFQ  \n",
       "86     2020-06-22    2373     88        29       techTFQ  \n",
       "\n",
       "[87 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data['Published_date'] = pd.to_datetime(video_data['Published_date']).dt.date\n",
    "video_data['Views'] = pd.to_numeric(video_data['Views'])\n",
    "video_data['Likes'] = pd.to_numeric(video_data['Likes'])\n",
    "video_data['Comments'] = pd.to_numeric(video_data['Comments'])\n",
    "video_data.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "video_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567c763-5dad-459a-b1a4-e4eebd220832",
   "metadata": {},
   "source": [
    "creating csv file for the data collected of different channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6f57f0d-fd42-42cf-8304-828a935f2d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#(for each channel the upper function has to run seperately)\n",
    "\n",
    "#video_data.to_csv('Apna_College_Video_details.csv')\n",
    "#video_data.to_csv('Code_with_harry_Video_details.csv')\n",
    "#video_data.to_csv('Buzzfeed_India_Video_details.csv')\n",
    "#video_data.to_csv('Monkey_Magic_Video_details.csv')\n",
    "#video_data.to_csv('techTFQ_Video_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "29dd973a-c809-4b08-b088-65fe23eda9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merging csv files\n",
    "df = pd.concat(map(pd.read_csv, ['Apna_College_Video_details.csv', \n",
    "                                 'Buzzfeed_India_Video_details.csv',\n",
    "                                 'Code_with_harry_Video_details.csv',\n",
    "                                 'Monkey_Magic_Video_details.csv',\n",
    "                                 'techTFQ_Video_details.csv']),\n",
    "               ignore_index=True)\n",
    "\n",
    "df.to_csv('All_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a13e9f1d-a037-4a4f-acfb-3ee94f46a024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Year']=pd.DatetimeIndex(df['Published_date']).year\n",
    "#df['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a36c608f-23f2-4833-9041-ade93a2443db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adding year column to MaindataFile.csv\n",
    "csv_input = pd.read_csv('All_data.csv')\n",
    "csv_input['Year'] =df['Year']\n",
    "csv_input.head()\n",
    "csv_input.to_csv(\"All_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d4ff2c5-5dd6-4706-9676-53de33c031e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing unwanted columns\n",
    "\n",
    "f=pd.read_csv(\"All_data.csv\")\n",
    "keep_col = ['Video_id','Title','Published_date','Views','Likes','Comments','Channel_Title','Year']\n",
    "new_f = f[keep_col]\n",
    "new_f.to_csv(\"MaindataFile.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
